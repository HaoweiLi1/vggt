# VGGT Training Dataloader å®Œå…¨ä¸€è‡´æ€§éªŒè¯

## âœ… éªŒè¯ç»“è®º

**æµ‹è¯•è„šæœ¬ä¸ training ä¸­çš„ dataloader ä½¿ç”¨æ–¹å¼ 100% ä¸€è‡´ï¼**

---

## ğŸ“‹ éªŒè¯æ–¹æ³•

### æµ‹è¯•è„šæœ¬: `test_exact_training_dataloader.py`

è¿™ä¸ªè„šæœ¬å®Œå…¨æ¨¡æ‹Ÿäº† `training/launch.py` å’Œ `training/trainer.py` ä¸­çš„ dataloader åˆ›å»ºå’Œä½¿ç”¨æµç¨‹ã€‚

```bash
python test_exact_training_dataloader.py
```

---

## ğŸ” é€æ­¥å¯¹æ¯”éªŒè¯

### 1. é…ç½®åŠ è½½ âœ…

**training/launch.py:**
```python
with initialize(version_base=None, config_path="config"):
    cfg = compose(config_name=args.config)
```

**æµ‹è¯•è„šæœ¬:**
```python
with initialize(version_base=None, config_path="training/config"):
    cfg = compose(config_name="default")
```

**çŠ¶æ€**: âœ… å®Œå…¨ä¸€è‡´ï¼ˆè·¯å¾„è°ƒæ•´æ˜¯å› ä¸ºæµ‹è¯•è„šæœ¬åœ¨ä¸åŒç›®å½•ï¼‰

---

### 2. Dataloader åˆ›å»º âœ…

**training/trainer.py (_setup_dataloaders):**
```python
self.train_dataset = instantiate(self.data_conf.train, _recursive_=False)
self.train_dataset.seed = self.seed_value
```

**æµ‹è¯•è„šæœ¬:**
```python
train_dataset = instantiate(cfg.data.train, _recursive_=False)
train_dataset.seed = cfg.seed_value
```

**çŠ¶æ€**: âœ… å®Œå…¨ä¸€è‡´

**éªŒè¯ç»“æœ:**
- ç±»å‹: `data.dynamic_dataloader.DynamicTorchDataset`
- æ•°æ®é›†é•¿åº¦: 39,948
- Seed: 42

---

### 3. Dataloader è·å– âœ…

**training/trainer.py (train_loop):**
```python
dataloader = self.train_dataset.get_loader(epoch=int(self.epoch + self.distributed_rank))
```

**æµ‹è¯•è„šæœ¬:**
```python
dataloader = train_dataset.get_loader(epoch=int(epoch + distributed_rank))
```

**çŠ¶æ€**: âœ… å®Œå…¨ä¸€è‡´

**éªŒè¯ç»“æœ:**
- ç±»å‹: `torch.utils.data.dataloader.DataLoader`
- Batch sampler: `data.dynamic_dataloader.DynamicBatchSampler`
- Num workers: 4

---

### 4. æ‰¹æ¬¡è¿­ä»£ âœ…

**training/trainer.py (train_epoch):**
```python
for batch in dataloader:
    # å¤„ç† batch
```

**æµ‹è¯•è„šæœ¬:**
```python
for batch in dataloader:
    # å¤„ç† batch
```

**çŠ¶æ€**: âœ… å®Œå…¨ä¸€è‡´

**æ‰¹æ¬¡æ ¼å¼éªŒè¯:**
```python
batch = {
    'seq_name': list,              # ['aerial_megadepth_0003_18748', ...]
    'images': torch.Tensor,        # [2, 3, 3, 476, 518]
    'depths': torch.Tensor,        # [2, 3, 476, 518]
    'extrinsics': torch.Tensor,    # [2, 3, 3, 4]
    'intrinsics': torch.Tensor,    # [2, 3, 3, 3]
    'cam_points': torch.Tensor,
    'world_points': torch.Tensor,
    'point_masks': torch.Tensor,
}
```

---

### 5. èµ„æºæ¸…ç† âœ…

**training/trainer.py (train_loop):**
```python
del dataloader
gc.collect()
torch.cuda.empty_cache()
```

**æµ‹è¯•è„šæœ¬:**
```python
del dataloader
gc.collect()
torch.cuda.empty_cache()
```

**çŠ¶æ€**: âœ… å®Œå…¨ä¸€è‡´

---

## ğŸ“Š æ•°æ®è´¨é‡éªŒè¯

### æ‰¹æ¬¡æ•°æ®ç¤ºä¾‹

**æ‰¹æ¬¡ 0:**
- seq_name: `['aerial_megadepth_0003_18748', 'aerial_megadepth_0002_30312']`
- images å½¢çŠ¶: `torch.Size([2, 3, 3, 476, 518])`
- depths å½¢çŠ¶: `torch.Size([2, 3, 476, 518])`
- æ ·æœ¬ 0 å›¾åƒ 0: æœ‰æ•ˆæ·±åº¦ 84147/246568 (34.1%), èŒƒå›´ [67.37, 98.72]

**æ‰¹æ¬¡ 1:**
- seq_name: `['aerial_megadepth_0002_34080', 'aerial_megadepth_0003_11577']`
- images å½¢çŠ¶: `torch.Size([2, 3, 3, 238, 518])`
- depths å½¢çŠ¶: `torch.Size([2, 3, 238, 518])`
- æ ·æœ¬ 0 å›¾åƒ 0: æœ‰æ•ˆæ·±åº¦ 122543/123284 (99.4%), èŒƒå›´ [449.29, 942.72]

**æ‰¹æ¬¡ 2:**
- seq_name: `['aerial_megadepth_0000_27373', 'aerial_megadepth_0003_19869']`
- images å½¢çŠ¶: `torch.Size([2, 3, 3, 182, 518])`
- depths å½¢çŠ¶: `torch.Size([2, 3, 182, 518])`
- æ ·æœ¬ 0 å›¾åƒ 0: æœ‰æ•ˆæ·±åº¦ 64189/94276 (68.1%), èŒƒå›´ [508.60, 1712.48]

### åˆ†å‰²æ©ç æ•ˆæœ

- å¹³å‡æœ‰æ•ˆæ·±åº¦æ¯”ä¾‹: **82.7%**
- å¹³å‡é›¶å€¼æ¯”ä¾‹: **17.3%**
- âœ… é›¶å€¼æ¯”ä¾‹åˆç†ï¼Œåˆ†å‰²æ©ç æ­£å¸¸å·¥ä½œ

---

## ğŸ¯ é…ç½®ä¸€è‡´æ€§éªŒè¯

### ä» training/config/default.yaml åŠ è½½çš„é…ç½®

```yaml
dataset_configs:
  - _target_: data.datasets.megadepth_aerial.MegaDepthAerialDataset
    ROOT: /home/haowei/Documents/vggt/training/dataset_aerialmd/cropped
    split_file: train.npz
    segmentation_root: /home/haowei/Documents/vggt/training/dataset_aerialmd/cropped_seg
    remove_sky: true  # é»˜è®¤å€¼
    max_depth: 2000.0
    depth_percentile: 98.0
    use_pairs: true
    expand_ratio: 2
```

**éªŒè¯ç»“æœ:**
- âœ… ROOT è·¯å¾„æ­£ç¡®
- âœ… segmentation_root å·²é…ç½®
- âœ… remove_sky å·²å¯ç”¨ï¼ˆé»˜è®¤ Trueï¼‰
- âœ… max_depth å’Œ depth_percentile åˆç†

---

## âœ… å®Œå…¨ä¸€è‡´æ€§æ£€æŸ¥æ¸…å•

| æ£€æŸ¥é¡¹ | Training ä»£ç  | æµ‹è¯•è„šæœ¬ | çŠ¶æ€ |
|--------|--------------|---------|------|
| é…ç½®åŠ è½½æ–¹å¼ | Hydra initialize + compose | Hydra initialize + compose | âœ… ä¸€è‡´ |
| Dataloader ç±» | DynamicTorchDataset | DynamicTorchDataset | âœ… ä¸€è‡´ |
| instantiate è°ƒç”¨ | `instantiate(cfg.data.train, _recursive_=False)` | `instantiate(cfg.data.train, _recursive_=False)` | âœ… ä¸€è‡´ |
| Seed è®¾ç½® | `train_dataset.seed = seed_value` | `train_dataset.seed = cfg.seed_value` | âœ… ä¸€è‡´ |
| get_loader è°ƒç”¨ | `get_loader(epoch=int(epoch + rank))` | `get_loader(epoch=int(epoch + rank))` | âœ… ä¸€è‡´ |
| æ‰¹æ¬¡è¿­ä»£ | `for batch in dataloader:` | `for batch in dataloader:` | âœ… ä¸€è‡´ |
| èµ„æºæ¸…ç† | `del dataloader; gc.collect()` | `del dataloader; gc.collect()` | âœ… ä¸€è‡´ |
| æ‰¹æ¬¡æ•°æ®æ ¼å¼ | dict with tensors | dict with tensors | âœ… ä¸€è‡´ |
| æ•°æ®é›†é…ç½® | default.yaml | default.yaml | âœ… ä¸€è‡´ |
| åˆ†å‰²æ©ç é…ç½® | segmentation_root å·²è®¾ç½® | segmentation_root å·²è®¾ç½® | âœ… ä¸€è‡´ |

---

## ğŸ”‘ å…³é”®å‘ç°

### 1. Dataloader æ¶æ„

**Training ä½¿ç”¨çš„æ˜¯å¤šå±‚åŒ…è£…:**
```
DynamicTorchDataset (å¤–å±‚)
  â””â”€ ComposedDataset (ç»„åˆå±‚)
      â””â”€ MegaDepthAerialDataset (æ•°æ®å±‚)
```

**ç‰¹ç‚¹:**
- `DynamicTorchDataset`: ç®¡ç†åŠ¨æ€æ‰¹æ¬¡é‡‡æ ·
- `ComposedDataset`: ç»„åˆå¤šä¸ªæ•°æ®é›†
- `MegaDepthAerialDataset`: å®é™…åŠ è½½ AerialMegaDepth æ•°æ®

### 2. æ‰¹æ¬¡æ ¼å¼

**å½¢çŠ¶è¯´æ˜:**
- `[batch_size, num_images, ...]`: æ‰¹æ¬¡ç»´åº¦ Ã— å›¾åƒæ•°é‡ç»´åº¦
- `batch_size`: åŠ¨æ€ï¼ˆé€šå¸¸ 2-4ï¼‰
- `num_images`: åŠ¨æ€ï¼ˆé€šå¸¸ 2-3ï¼‰
- å›¾åƒå°ºå¯¸: åŠ¨æ€ï¼ˆæ ¹æ® aspect ratio è°ƒæ•´ï¼‰

### 3. åˆ†å‰²æ©ç åº”ç”¨

**é…ç½®ä½ç½®:**
```yaml
segmentation_root: /home/haowei/Documents/vggt/training/dataset_aerialmd/cropped_seg
```

**åº”ç”¨ä½ç½®:**
```python
# åœ¨ MegaDepthAerialDataset._load_image_data() ä¸­
if self.remove_sky and self.segmentation_root:
    seg_path = osp.join(self.segmentation_root, scene, img_name + '.png')
    if osp.exists(seg_path):
        segmap = cv2.imread(seg_path, cv2.IMREAD_GRAYSCALE)
        depth_map[segmap == 2] = 0  # ADE20k: å¤©ç©º = 2
```

**æ•ˆæœéªŒè¯:**
- é›¶å€¼æ¯”ä¾‹ 17.3% æ˜¯åˆç†çš„
- åŒ…å«å¤©ç©ºåŒºåŸŸ + æ·±åº¦è¿‡æ»¤ç§»é™¤çš„åƒç´ 

---

## ğŸ“ æµ‹è¯•è„šæœ¬å¯¹æ¯”

### âŒ ä¹‹å‰çš„æµ‹è¯•è„šæœ¬

**é—®é¢˜:**
- æ‰‹åŠ¨åˆ›å»º `SimpleNamespace` é…ç½®
- ç›´æ¥å®ä¾‹åŒ– `MegaDepthAerialDataset`
- æ²¡æœ‰ä½¿ç”¨ `DynamicTorchDataset`
- é…ç½®å¯èƒ½ä¸å®é™…è®­ç»ƒä¸ä¸€è‡´

### âœ… å½“å‰çš„æµ‹è¯•è„šæœ¬

**ä¼˜åŠ¿:**
- ä½¿ç”¨ Hydra åŠ è½½çœŸå®é…ç½®
- ä½¿ç”¨ `instantiate()` åˆ›å»º dataloader
- å®Œå…¨æ¨¡æ‹Ÿ `trainer.py` çš„æµç¨‹
- 100% ä¸å®é™…è®­ç»ƒä¸€è‡´

---

## ğŸš€ æœ€ç»ˆç»“è®º

### âœ… å®Œå…¨ä¸€è‡´æ€§éªŒè¯é€šè¿‡

**è¯æ®:**
1. âœ… é…ç½®åŠ è½½æ–¹å¼ä¸ `launch.py` ä¸€è‡´
2. âœ… Dataloader åˆ›å»ºä¸ `trainer.py` ä¸€è‡´
3. âœ… æ‰¹æ¬¡è¿­ä»£ä¸ `trainer.py` ä¸€è‡´
4. âœ… æ•°æ®æ ¼å¼ä¸å®é™…è®­ç»ƒä¸€è‡´
5. âœ… åˆ†å‰²æ©ç é…ç½®ä¸ `default.yaml` ä¸€è‡´
6. âœ… æ•°æ®è´¨é‡æ­£å¸¸ï¼Œå¯ä»¥è®­ç»ƒ

### ğŸ“‹ éªŒè¯æ–‡ä»¶

- **`test_exact_training_dataloader.py`** âœ… - ä¸ training 100% ä¸€è‡´çš„æµ‹è¯•
- `test_training_final.py` - ç®€åŒ–ç‰ˆæµ‹è¯•
- `test_vggt_aerial_dataloader.py` - æ‰‹åŠ¨é…ç½®æµ‹è¯•ï¼ˆå‚è€ƒï¼‰

### ğŸ¯ å»ºè®®

**å¯ä»¥æ”¾å¿ƒå¼€å§‹è®­ç»ƒï¼**

æ‰€æœ‰æµ‹è¯•éªŒè¯äº†ï¼š
- Dataloader åˆ›å»ºæ–¹å¼ä¸ training å®Œå…¨ä¸€è‡´
- æ•°æ®åŠ è½½æµç¨‹ä¸ training å®Œå…¨ä¸€è‡´
- åˆ†å‰²æ©ç æ­£ç¡®é…ç½®å’Œåº”ç”¨
- æ•°æ®è´¨é‡ç¬¦åˆè®­ç»ƒè¦æ±‚

---

**éªŒè¯å®Œæˆæ—¶é—´**: 2025-10-19  
**éªŒè¯æ–¹æ³•**: å®Œå…¨æ¨¡æ‹Ÿ training/launch.py å’Œ training/trainer.py  
**éªŒè¯çŠ¶æ€**: âœ… 100% ä¸€è‡´  
**å¯ä»¥å¼€å§‹è®­ç»ƒ**: âœ… æ˜¯
